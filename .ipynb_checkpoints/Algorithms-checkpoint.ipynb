{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Algorithms Reference Book</h1>\n",
    "<h2>A personal reference to accompany the <a href=\"https://www.manning.com/books/grokking-algorithms\"> Grokking Algorithms textbook</a></h2>\n",
    "This jupyter notebook serves a reference to the Grokking Algorithms illustrated guide, and lays out examples of the algorithms discussed within its text, demonstrated in Python. The intended purpose is to be a helpful guide for myself and others to refer too for revision. A bit like a cheatsheet. I would highly recommend the mentioned book, and here I will expand upon it by providing python examples, and discusing additional resources for the advanced topics that are touched upon in the final chapter.\n",
    "\n",
    "I won't be talking about data structures much here, but they are vital to good algorithm design. Data structures are covered heavily in the text, but for more info see:\n",
    "* <a href=\"https://www.youtube.com/watch?v=NptnmWvkbTw\">Arrays</a>\n",
    "* <a href=\"https://www.youtube.com/watch?v=_jQhALI4ujg\">Linked lists</a>\n",
    "* <a href=\"https://www.youtube.com/watch?v=FNZ5o9S9prU\">Stacks</a>\n",
    "* <a href=\"https://www.youtube.com/watch?v=shs0KM3wKv8\">Hash Tables</a>\n",
    "\n",
    "I will be covering trees and heaps later on because they are not covered in the text, and I would like to expand on my own understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Big O Notation</h3>\n",
    "First some quick notes on Big O Notation:\n",
    "* Algorithm speed isn't measured in time, but in terms of **growth** of an algorithm\n",
    "* Algorithm times are written in Big O Notation\n",
    "* Big O establishes a worst-case run time\n",
    "* Common Big O Notations:\n",
    "    * O(log n) - known as log time, example: Binary Search\n",
    "    * O(n) - known as linear time, example: Simple Search\n",
    "    * O(n * log n) - an example would be a fast sorting algorithm like quicksort\n",
    "    * O(n^2) - an example would be a slow sorting algorithm like selection sort\n",
    "    * O(n!) - n factorial, this is a really slow algorithm, like with the travelling salesperson problem\n",
    "* For more examples, see http://bigocheatsheet.com/ or https://www.youtube.com/watch?v=v4cd1O4zkGw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Binary Search</h3>\n",
    "If you have a sorted array, binary search provides a rapid means of searching its contents. \n",
    "* Much faster than simple search (serial search)\n",
    "* Worst case scenario binary search is O(log n) wheras simple search is O(n) i.e. in the worst case scenario you will have to search through every element\n",
    "* Binary search ONLY works on **sorted** arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_search(array, query):\n",
    "    start = 0\n",
    "    finish = len(array) - 1\n",
    "    while start <= finish:\n",
    "        mid = start + finish\n",
    "        guess = array[mid]\n",
    "        if guess == query:\n",
    "            return mid\n",
    "        if guess > query:\n",
    "            finish = mid - 1\n",
    "        else:\n",
    "            start = mid + 1\n",
    "    return None #If the item doesn't exist, return none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_list = [\"apple\", \"bananna\", \"chips\", \"coconut\", \"grapes\", \"peanuts\", \"watermelon\"]\n",
    "num_list = [2,5,11,23,43,56,89,124,254]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(alpha_list, \"chips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(num_list, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Selection Sort</h3>\n",
    "This algorithm can be used for sorting elements by size, and the principle is that you find the smallest/largest element, and then add this element to a new list, and then repeat. The problem is this is very slow. You have to find each element, which takes O(n) time, and then add that element to a new list, which also takes O(n) time. This algorithm will therefore take O(n^2) time to complete. The example below is sorting a list from smallest to largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unsorted_numbers = [3,76,23,245,63,12,46,9,5,245,32,46,30,22,55,312]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_smallest(array):\n",
    "    smallest = array[0]\n",
    "    smallest_idx = 0\n",
    "    for i in range(1, len(array)):\n",
    "        if array[i] < smallest:\n",
    "            smallest = array[i]\n",
    "            smallest_idx = i\n",
    "    return smallest_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selection_sort(array):\n",
    "    new_array = []\n",
    "    for i in range(len(array)):\n",
    "        smallest = find_smallest(array)\n",
    "        new_array.append(array.pop(smallest))\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 9, 12, 22, 23, 30, 32, 46, 46, 55, 63, 76, 245, 245, 312]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_sort(unsorted_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Recursion</h3>\n",
    "A function that calls itself, this is the essence of recursion. When writing a recursive algorithm, you need to establish two cases:\n",
    "* The base case: this is what your intended goal is, and when it returns true you stop recursion\n",
    "* The recursive case: the condition in which the function will call itself\n",
    "Using recursion requires understanding stacks, in particular call stacks, and this is covered very neatly in the aforementioned book, otherwise you can google it, as there are lots of great explanations.\n",
    "\n",
    "Recursion doesn't provide any performance benefits but makes for neater and similier code. It is also an important concept used by other algorithms, for example quicksort which will be discussed later.\n",
    "\n",
    "Recursion also comes with a cost, as each function call is added to the stack and is therefore taking up memory. If the stack gets too tall, you might need to rewrite the code as loops or use tail recursion.\n",
    "\n",
    "I will now produce the first 10 elements of the fibonacci sequence using loops and then with recursion to demonstrate the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "13\n",
      "21\n",
      "34\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "#Fibonacci with loops \n",
    "\n",
    "x = 0\n",
    "y = 1\n",
    "for i in range(10):\n",
    "    print(y)\n",
    "    old_x = x\n",
    "    x = y\n",
    "    y = old_x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1)+fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "13\n",
      "21\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(fib(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of more examples from the exercises in the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_array(array):\n",
    "    if array == []:\n",
    "        return 0\n",
    "    else:\n",
    "        return array[0] + sum(array[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = [2,64,2,3]\n",
    "sum_array(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length(array):\n",
    "    if array == []:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 + length(array[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
    "length(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>QuickSort</h3>\n",
    "This is a sorting algorithm that is much faster than selection sort, and uses recursion to achieve its processing. First we chose a base case; what is the easiest array we could sort, which is an array containing only a single element. Then we make our recursion case, which involves chosing a **pivot**, which is a point where we divide the array into two, and then we call the quicksort algorithm on the two sub-arrays.\n",
    "\n",
    "Some extra notes:\n",
    "* Choose a random element as the pivot\n",
    "* The average runtime is O(n log n)\n",
    "* Use the divide an conquer strategy when developing algorithms with recursion. Find the base case, this is the simpiliest case to solve, and then use recursion to get to the base case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def quicksort(array):\n",
    "    if len(array) < 2:\n",
    "        return array\n",
    "    else:\n",
    "        pivot = array[randint(0, len(array)-1)]\n",
    "        less = [i for i in array[1:] if i <= pivot]\n",
    "        greater = [i for i in array[1:] if i > pivot]\n",
    "        return quicksort(less) + [pivot] + quicksort(greater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 9, 22, 30, 32, 32, 46, 55, 55, 55, 63, 245, 245, 245, 312]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quicksort(unsorted_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Closure</h3>\n",
    "Closures are awesome! I used them previously in the UTI data project you can find in my github. The principle is that you define a function that returns a function, and the funtion is stored along with its enviroment and captured variables. This mean, that when you call the function later on you can access these captured variables even though they are outside the current scope.\n",
    "\n",
    "Below is the example that can be found on <a href=\"https://en.wikipedia.org/wiki/Closure_(computer_programming)\">this</a> wikipedia entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def start(x):\n",
    "    def increment_by(y):\n",
    "        return x + y\n",
    "    return increment_by\n",
    "#The value 10 is stored within x, that is \n",
    "closure = start(10)\n",
    "closure(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Breadth-first search</h3>\n",
    "Breadth-first search algorithms are used for finding if a path exists, and the shortest possible path in an unweighted graph. The function below is an implementation of breadth-first search in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load breadth_first.py\n",
    "\n",
    "import collections\n",
    "\n",
    "def search(start_point, query_function, graph):\n",
    "    \"\"\"Params:\n",
    "        start_point: starting node, must be an existing key in graph\n",
    "        query_function: function to pass search queries, must return boolean value\n",
    "        graph: graph to search. Expects hash table datatype\"\"\"\n",
    "    queue = collections.deque()\n",
    "    queue += graph[start_point]\n",
    "    searched = []\n",
    "\n",
    "    while queue:\n",
    "        query = queue.popleft()\n",
    "        if not query in searched:\n",
    "            if query_function(query):\n",
    "                print(\"Matching node found!\")\n",
    "                return {\"query_node\": query, \"path\": searched}\n",
    "        else:\n",
    "            queue += graph[query]\n",
    "            searched.append(query)\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on breadth first search:\n",
    "* Tells you if there is a path from A to B\n",
    "* If a path exists, it will find the shortest path\n",
    "* When relating to distance, try modeling a problem as a graph\n",
    "* A directed graph has arrows, and the relationship follows the arrows\n",
    "* Undirected graphs don't have arrows and the relationship goes both ways\n",
    "* Queues are FIFO (first in first out)\n",
    "* Stacks are LIFO (last in first out)\n",
    "* When doing breadth first, use a queue, need to check objects in the order they were added to the search list, otherwise you won't get the shortest path\n",
    "* Make sure not to check objects twice, or else you will get an infinite loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dijkstra's Algorithm</h3>\n",
    "Dijkstra's (pronounced deyek-stra) algorithm is for finding the shortest possible path in weighted directed acyclic graphs. NOTE: Dijkstra's algorithm does not work on graphs with negative weighted edges. See the Bellman-ford algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Dijkstras_Algorithm.py\n",
    "class Dijkstra:\n",
    "    def __init__(self, graph):\n",
    "        \"\"\"Initialise Dijkstra search.\n",
    "        Params:\n",
    "            Graph: should be a nested dictionary detailing nodes, neighbours\n",
    "            and weights for edges connecting nodes and neighbours\"\"\"\n",
    "        if istype(graph) is dict:\n",
    "            self.graph = graph\n",
    "        else:\n",
    "            print(\"Graph of invalid datatype\")\n",
    "            break\n",
    "        self.infinity = float(\"inf\")\n",
    "\n",
    "    def init_costs(self, start_node):\n",
    "        #We only know the costs for the neighbours of the starting node\n",
    "        #Set all other nodes to infinity\n",
    "        costs = {}\n",
    "        for node in self.graph:\n",
    "            if node == start_node:\n",
    "                for k, v in node.items():\n",
    "                    costs[k] = v\n",
    "            else:\n",
    "                for k, v in node:\n",
    "                    costs[k] = self.infinity\n",
    "        return costs\n",
    "\n",
    "    def init_parents(self, start_node):\n",
    "        #Set the parent of neighbours to start node\n",
    "        parents = {}\n",
    "        for k, v in self.graph[start_node].items():\n",
    "            parents[k] = \"start\"\n",
    "        return parents\n",
    "\n",
    "    def find_lowest_cost_node(self, costs, processed_nodes):\n",
    "        lowest_cost = float(\"inf\")\n",
    "        lowest_cost_node = None\n",
    "        for node in costs:\n",
    "            cost = costs[node]\n",
    "            if cost < lowest_cost_node and node not in processed_nodes:\n",
    "                lowest_cost = cost\n",
    "                lowest_cost_node = node\n",
    "        return lowest_cost_node\n",
    "\n",
    "    def find_shortest_path(self, start_node):\n",
    "        costs = self.init_costs(start_node)\n",
    "        parents = self.parents(start_node)\n",
    "        processed = []\n",
    "        node = self.find_lowest_cost_node(costs, processed)\n",
    "\n",
    "        while node is not None:\n",
    "            cost = costs[node]\n",
    "            neighbours = self.graph[node]\n",
    "            for n in neighbours.keys():\n",
    "                new_cost = cost + neighbours[n]\n",
    "                if costs[n] > new_cost:\n",
    "                    costs[n] = new_cost\n",
    "                    parents[n] = node\n",
    "            processed.append(node)\n",
    "            node = find_lowest_cost_node(costs, processed)\n",
    "        return parents, costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on Dijkstra's Algorithm:\n",
    "* Breadth-first search is used to calculate the shortest path for an unweighted graph\n",
    "* Dijkstra's algorithm is used to calculate the shortest path for a weighted graph\n",
    "* Dijkstra's algorithm only works when all weights are positive, otherwise use Bellman-Ford algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Greedy Algorithms</h3>\n",
    "Sometime's you cannot solve an algorithm for the general optimal solution, and so you want to create an algorithm that is just good enough, but is also quick. This is where greedy algorithms come into play. Greedy algorithms aim to give an approximation to the optimal solution whilst also being fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The Set-covering Problem</h4>\n",
    "Say for example: you have a radio show and you want to reach listeners in all 50 of the US states. You need to decide what stations to play on to reach all those listeners. It costs money to be on each station so you want to minimise the number of stations you play on but get the biggest outreach possible.\n",
    "\n",
    "You could list every possible subset of stations (the power set) and pick the set with the smallest number of stations that covers all 50 states, but there would be a total of 2^n possible subsets, and this could take a long time to calculate. So it would be better to use a greedy algorithm that approximates a reasonible answer. We can do this by picking a station that covers most of the states that haven't been covered yet (even if it overlaps with some other stations in regards to states that have been covered) and then repat until we have coverage over every state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup\n",
    "states_needed = set([\"mt\", \"wa\", \"or\", \"id\", \"nv\", \"ut\"])\n",
    "stations = {\n",
    "    \"kone\": set([\"id\", \"nv\", \"ut\"]),\n",
    "    \"ktwo\": set([\"wa\", \"id\", \"mt\"]),\n",
    "    \"kthree\": set([\"or\", \"nv\", \"ca\"]),\n",
    "    \"kfour\": set([\"nv\", \"ut\"]),\n",
    "    \"kfive\": set([\"ca\", \"az\"])\n",
    "}\n",
    "final_stations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while states_needed:\n",
    "    best_station = None\n",
    "    states_covered = set()\n",
    "    for station, states in stations.items():\n",
    "        covered = states_needed & states #This is called set intersection, see below!\n",
    "        if len(covered) > len(states_covered):\n",
    "            best_station = station\n",
    "            states_covered = covered\n",
    "    states_needed -= states_covered\n",
    "    final_stations.append(best_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kone', 'ktwo', 'kthree']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set union/intersection/difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_one = set([1,3,5,8,19,25,34])\n",
    "set_two = set([1,3,15,19,23,25,42,68])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 3, 5, 8, 15, 19, 23, 25, 34, 42, 68}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set union\n",
    "set_one | set_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 3, 19, 25}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set intersection\n",
    "set_one & set_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5, 8, 34}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set difference\n",
    "set_one - set_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>NP-Complete Problems</h4>\n",
    "\n",
    "The problem above is very similar to the 'travelling salesperson' problem. The optimal solution involves calculating every possible solution and picking the smallest/shortest one. Problems like this are called NP-complete problems. (Btw, NP stands for \"nondeterministic polynomial time\").\n",
    "\n",
    "As soon as you realise that a problem is an NP-problem, you should stop trying to solve it perfectly, and instead focus your efforts on making a good approximation. There is no easy way of telling if a probelm is NP-complete, but here are some giveaways:\n",
    "* Your algorithm is quick when processing a few items, but soon deterioates when you add more items\n",
    "* \"All combinations of X\" usually points to an NP-complete problem\n",
    "* You can't break something down into sub-problems and so you have to calculate \"every possible version of X\".\n",
    "* The problem involves a sequence and is difficult to solve (such as the travelling salesperson)\n",
    "* If the problem involves a set and is difficult to solve (like the set-covering problem)\n",
    "* If you can restate the problem like it is the travelling salesperson problem or the set-covering problem, then it is definitely NP-complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on Greedy Algorithms:\n",
    "* They optimise locally, hoping to end up with a global optimum\n",
    "* NP-complete problems have no known fast solution\n",
    "* If you have an NP-complete problem, your best bet is to use an approximation algorithm\n",
    "* Greedy algorithms are simple and fast to run, so they make for good approximation algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Dynamic Programming</h3>\n",
    "The process of dynamic programming involves breaking up a task into subproblems whose solutons can be used to solve a larger problem. Dynamic programming is useful when you're trying to optimize something given a constrant. For example, if you need too fit a certain number of goods of different values in a storage unit, and you are constrained by the weight of the goods, but you want to optimize the value stored.\n",
    "\n",
    "Some important notes about dynamic programming:\n",
    "* You can use dynamic programming only when the problem can be broken down into discrete subproblems, and these subproblems do not depend upon one another\n",
    "* Every dynamic programming solution involves a grid\n",
    "* The values in the cells of this grid are usually what you're trying to optimize\n",
    "* Each cell is a subproblem, so think about how you can divide your problem into subproblems, and this will help you figure out what the axes are\n",
    "\n",
    "An example of dynamic programming is seeing if two words are similar to one another based on common substrings. Say someone mispelt 'fish' as 'hish' and you want to see if it is closer to the word 'fish' or 'vista', then you can use dynamic programming to determine which contains the longest common substring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Longest common substring - if the letters match, take the value of the top left cell and add one\n",
    "import numpy as np\n",
    "def longest_com_substring(word_a, word_b):\n",
    "    grid = np.zeros((len(word_a), len(word_b)))\n",
    "    for i in range(0, len(word_a)):\n",
    "        for j in range(0, len(word_b)):\n",
    "            if word_a[i] == word_b[j]:\n",
    "                grid[i][j] = grid[i-1][j-1] + 1\n",
    "            else:\n",
    "                grid[i][j] = 0\n",
    "    print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  2.  0.]\n",
      " [ 1.  0.  0.  3.]]\n"
     ]
    }
   ],
   "source": [
    "word_a = \"fish\"\n",
    "word_b = \"hish\"\n",
    "longest_com_substring(word_a, word_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  2.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "word_a = \"hish\"\n",
    "word_b = \"vista\"\n",
    "longest_com_substring(word_a, word_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But say instead of looking for the longest common substring, you wanted to know how many letters the two words have in common; the longest common subsequence. For this you would use a similar but slightly adapted method. The words \"fosh\" for example has the same longest common substring for both \"fish\" and \"fort\", but has more matching letters with \"fist\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  2.]]\n"
     ]
    }
   ],
   "source": [
    "word_a = \"fosh\"\n",
    "word_b = \"fish\"\n",
    "longest_com_substring(word_a, word_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  2.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "word_a = \"fosh\"\n",
    "word_b = \"fort\"\n",
    "longest_com_substring(word_a, word_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Longest common subsequence - if the letters match, take the value of the top left cell and add one, if they don't match\n",
    "#take the largest value from either the left or from above\n",
    "def longest_com_subseq(word_a, word_b):\n",
    "    grid = np.zeros((len(word_a), len(word_b)))\n",
    "    for i in range(0, len(word_a)):\n",
    "        for j in range(0, len(word_b)):\n",
    "            if word_a[i] == word_b[j]:\n",
    "                grid[i][j] = grid[i-1][j-1] + 1\n",
    "            else:\n",
    "                grid[i][j] = max(grid[i-1][j], grid[i][j-1])\n",
    "    print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.]\n",
      " [ 1.  1.  2.  2.]\n",
      " [ 1.  1.  2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "word_a = \"fosh\"\n",
    "word_b = \"fish\"\n",
    "longest_com_subseq(word_a, word_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.]\n",
      " [ 1.  2.  2.  2.]\n",
      " [ 1.  2.  2.  2.]\n",
      " [ 1.  2.  2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "word_a = \"fosh\"\n",
    "word_b = \"fort\"\n",
    "longest_com_subseq(word_a, word_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  1.]\n",
      " [ 0.  1.  2.  2.  2.]\n",
      " [ 0.  1.  2.  3.  3.]\n",
      " [ 0.  1.  2.  3.  4.]]\n"
     ]
    }
   ],
   "source": [
    "word_a = \"blues\"\n",
    "word_b = \"clues\"\n",
    "longest_com_subseq(word_a, word_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice string simularity is determined using the Levenshtein distance algorithm. This uses dynamic programming and is found in everything from spell check too detecting copyrighted information.\n",
    "\n",
    "Note, there is no single formula for calculating a dynamic programming solution, instead there is just a common theme: use a grid and breakdown the problem into subproblems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>K-Nearest Neighbour</h3>\n",
    "The principle of KNN is to classify a previously unclassified data or predict a value, based on other data with similar features. This is achieved by calculating the distance in euclidean space between what you're trying to classify/predict and its 'neaighbours', for which you already have the desired information.\n",
    "\n",
    "So KNN can be used for the following tasks:\n",
    "* Classification: grouping data based on previous information on 'similar' data\n",
    "* Regression: predicting the value of some unknown variable based on information from 'similar' data\n",
    "\n",
    "KNN is a machine learning algorithm. Ther e are many types of machine learning algorithms, some of which I have examples of in the DataQuest Projects repo that can be found on my github. For any machine learning algorithm, feature extraction, engineering, and chosing the correct features, is vital to successful predictions.\n",
    "\n",
    "When performing machine learning tasks KNN is not always the ideal choice. KNN is best suited too simple problems with small datasets. It is a computationally expensive algorithm because for each query you need to calculate the euclidean distance to each training sample. Therefore, when using larger datasets it is best to use an algorithm that 'describes' the relationships that exist within the data itself. For this linear/logistic regression is helpful, as well as tree structures or graphs.\n",
    "\n",
    "To see an example of KNN in action using the SciKit learn library please refer to this <a href=\"https://tinyurl.com/yc4vj6bk\">notebook</a>\n",
    "\n",
    "Other machine learning algorithms and examples in python can be found <a href=\"https://github.com/burtonbiomedical/DataQuest_Projects/tree/master/Machine%20Learning\">here</a>. A huge thank you to www.dataquest.io for a comprehensive overview of machine learning with a project based approach, which is what I used to create the linked repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Advanced Topics</h2>\n",
    "The final chapter of the Mannings Algorithms book covers 10 more advance algorithms, and is a very interesting read, but it doesn't provide any in-depth descritions. Below are some resources for the topics covered in this chapter:\n",
    "* Trees:\n",
    "    * <a href=\"https://www.youtube.com/watch?v=qH6yxkw0u78\">Introduction to trees</a>\n",
    "    * <a href=\"http://btechsmartclass.com/DS/U5_T3.html\">B-Trees</a>\n",
    "    * <a href=\"https://www.tutorialspoint.com/data_structures_algorithms/heap_data_structure.htm\">Heaps</a>\n",
    "* <a href=\"https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/\">The Fourier Transform</a>\n",
    "* MapReduce: this is an example of parallel programming that allows for distributed computing. I have personally only had exposure to Apache Spark when it comes to distributed computing, and a good tutorial to get started with the python API for Apache Spark can be found <a href=\"https://www.dezyre.com/apache-spark-tutorial/pyspark-tutorial\">here.</a> The map and reduce functions have implementations in python however, demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 9, 15, 18, 9, 18, 9]\n"
     ]
    }
   ],
   "source": [
    "array_one = [2,3,5,6,3,6,3]\n",
    "array_two = list(map(lambda x: 3*x, array_one))\n",
    "print(array_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9720\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "reduced = reduce(lambda x,y: x*y, array_one)\n",
    "print(reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probabilistic algorithms    \n",
    "    * <a href=\"https://www.youtube.com/watch?v=U8Ni1yJ8ZS4\">Bloom Filter</a>\n",
    "    * <a href=\"https://www.youtube.com/watch?v=ZRCLZ3aIaVU\">HyperLogLog</a>\n",
    "* <a href=\"http://www.pythoncentral.io/hashing-strings-with-python/\">Hashing Algorithms in Python</a>\n",
    "* Linear Programming\n",
    "    * <a href=\"https://www.analyticsvidhya.com/blog/2017/02/lintroductory-guide-on-linear-programming-explained-in-simple-english/\">Introduction</a>\n",
    "    * <a href=\"http://benalexkeen.com/linear-programming-with-python-and-pulp/\">Linear Programming in Python</a>\n",
    "\n",
    "And finally, two just incredible resources:\n",
    "* https://betterexplained.com/archives/\n",
    "* https://www.tutorialspoint.com/data_structures_algorithms/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
